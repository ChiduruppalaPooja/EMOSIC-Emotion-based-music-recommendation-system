# ![datacollection.py](https://github.com/ChiduruppalaPooja/EMOSIC-Emotion-based-music-recommendation-system/blob/main/datacollection.py) file Output
This file is used to collect data from the user through camera. We have to enter the mood/emotion manually and store it in a .npy file
### This is the output of the data
![](https://github.com/ChiduruppalaPooja/EMOSIC-Emotion-based-music-recommendation-system/blob/main/Screenshots/datacollection%20output/datacollectionop.JPG)


# ![data_training.py](https://github.com/ChiduruppalaPooja/EMOSIC-Emotion-based-music-recommendation-system/blob/main/data_training.py) file Output
This file is used to train the model and is run over 50 epochs the model.h5 and labels.npy file is then saved
### The screenshot of the output of this file
![](https://github.com/ChiduruppalaPooja/EMOSIC-Emotion-based-music-recommendation-system/blob/main/Screenshots/data_training%20output/accuracy.JPG)
![](https://github.com/ChiduruppalaPooja/EMOSIC-Emotion-based-music-recommendation-system/blob/main/Screenshots/data_training%20output/accuracy2.JPG)
![](https://github.com/ChiduruppalaPooja/EMOSIC-Emotion-based-music-recommendation-system/blob/main/Screenshots/data_training%20output/accuracy3.JPG)


# ![data_inference.py](https://github.com/ChiduruppalaPooja/EMOSIC-Emotion-based-music-recommendation-system/blob/main/data_inference.py)file Output
This shows the working of the model
### The screenshot of the output of this file
![](https://github.com/ChiduruppalaPooja/EMOSIC-Emotion-based-music-recommendation-system/blob/main/Screenshots/data_inference%20output/data_inferenceop.JPG)
